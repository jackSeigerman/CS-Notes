# COMP 231 INTRO SYS PROGRM & COMP ORG

- Instructor: Nate Phillips
- Notes Written by: Jack Seigerman
- Year: Fall 2024

## Von Neumon architechture

The Von Neumann architecture is a computer architecture model that describes a system where the computer's memory holds both instructions and data. This architecture is based on the stored-program concept, where instructions to be executed by the computer are represented as binary values and stored in memory.

### Key Components:
1. **Central Processing Unit (CPU)**: Executes instructions.
2. **Memory**: Stores data and instructions.
3. **Input/Output (I/O) Devices**: Allow interaction with the external environment.
4. **Buses**: Communication pathways for data transfer.

### Characteristics:
- **Single Memory**: Both instructions and data are stored in the same memory space.
- **Sequential Execution**: Instructions are processed sequentially unless altered by control instructions.
- **Fetch-Decode-Execute Cycle**: The CPU fetches an instruction from memory, decodes it, and then executes it.

### Advantages:
- Simplifies the design and development of the control unit.
- Flexibility in programming as instructions can be modified by the program itself.

### Disadvantages:
- **Von Neumann Bottleneck**: The shared bus for data and instructions can become a bottleneck, limiting performance.
- **Security Risks**: Since instructions and data share the same memory, it can lead to vulnerabilities.

### Applications:
- General-purpose computers.
- Embedded systems with simple control requirements.

The Von Neumann architecture has been fundamental in the development of modern computers and continues to influence computer design.

> Most importantly, it is reprogrammable.

### Performance Hierarchy:
- **Slowest to Fastest**: I/O, Memory, Registers

To access a piece of memory, the CPU needs to send the address over the address bus and receive data back from memory over the data bus.

### Other Models:
- **Harvard Model**
- **Neural Model**
- **DSPs**
- **Cellular Automata**

### Parallel Computing:
- **Amdahl's Law**: Speedup is limited to the proportion of time that is not sequential, which is the maximum you can speed up a workload.

### Data Units:
- **Bit**: 0 or 1 (high +5V, or low 0V)
- **Byte**: 8 bits (octet)
- **Word**: 8 bits to 16 bits (Windows 3.1) to 32 bits (XP MSX) to 64 bits (modern)
- **Nibble**: 4 bits

### Number Systems:
- **Decimal**: Radix 10
- **Binary**: Radix 2
- **Octal**: Radix 8
- **Hexadecimal**: Radix 16


## Converting Between Number Systems

Converting numbers from one base to another can be done using a general method that involves converting the original number to a base-10 (decimal) number first, and then converting the decimal number to the desired base. This method can be applied to any number system.

### Steps for Conversion:

1. **Convert to Decimal (Base-10)**:
    - Identify the base of the original number.
    - Multiply each digit of the original number by the base raised to the power of the digit's position (starting from 0 on the right).
    - Sum all the results to get the decimal equivalent.

2. **Convert from Decimal to Desired Base**:
    - Identify the desired base.
    - Divide the decimal number by the desired base.
    - Record the remainder.
    - Update the decimal number to the quotient of the division.
    - Repeat the division process until the quotient is zero.
    - The remainders, read in reverse order, form the number in the desired base.

### Example 1: Convert Binary (Base-2) to Hexadecimal (Base-16)

1. **Binary to Decimal**:
    - Binary number: `1011`
    - Calculation: \(1 \times 2^3 + 0 \times 2^2 + 1 \times 2^1 + 1 \times 2^0 = 8 + 0 + 2 + 1 = 11\)
    - Decimal equivalent: `11`

2. **Decimal to Hexadecimal**:
    - Decimal number: `11`
    - Calculation: \(11 \div 16 = 0\) remainder `11`
    - Hexadecimal equivalent: `B`

### Example 2: Convert Octal (Base-8) to Binary (Base-2)

1. **Octal to Decimal**:
    - Octal number: `17`
    - Calculation: \(1 \times 8^1 + 7 \times 8^0 = 8 + 7 = 15\)
    - Decimal equivalent: `15`

2. **Decimal to Binary**:
    - Decimal number: `15`
    - Calculation: \(15 \div 2 = 7\) remainder `1`, \(7 \div 2 = 3\) remainder `1`, \(3 \div 2 = 1\) remainder `1`, \(1 \div 2 = 0\) remainder `1`
    - Binary equivalent: `1111`

### Example 3: Convert Hexadecimal (Base-16) to Decimal (Base-10)

1. **Hexadecimal to Decimal**:
    - Hexadecimal number: `1A`
    - Calculation: \(1 \times 16^1 + A \times 16^0 = 1 \times 16 + 10 \times 1 = 16 + 10 = 26\)
    - Decimal equivalent: `26`



## Truth Tables and Karnaugh Maps (K-Maps)

### Truth Tables

A truth table is a mathematical table used to determine the output of a particular digital logic circuit or Boolean expression for all possible input values. It lists all possible combinations of input values and the corresponding output values.

#### How to Create a Truth Table:
1. **Identify Variables**: Determine the number of input variables (e.g., A, B, C).
2. **List Combinations**: List all possible combinations of input values (0 and 1).
3. **Determine Outputs**: Calculate the output for each combination based on the logic circuit or Boolean expression.

#### Example:
For a simple AND gate with inputs A and B:
| A | B | A AND B |
|---|---|---------|
| 0 | 0 |    0    |
| 0 | 1 |    0    |
| 1 | 0 |    0    |
| 1 | 1 |    1    |

### Karnaugh Maps (K-Maps)

Karnaugh Maps are a visual method for simplifying Boolean expressions and minimizing logic circuits. They help in reducing the number of gates required by grouping adjacent cells representing minterms.

#### How to Create a K-Map:
1. **Determine Variables**: Identify the number of variables.
2. **Draw Grid**: Create a grid with 2^n cells for n variables.
3. **Fill Values**: Fill in the cells with the output values from the truth table.
4. **Group Minterms**: Group adjacent cells with value 1 into the largest possible power-of-two rectangles.
5. **Simplify Expression**: Write the simplified Boolean expression from the groups.

#### Example:
For a 2-variable K-Map:
| AB | 00 | 01 | 11 | 10 |
|----|----|----|----|----|
|  0 |  1 |  0 |  1 |  0 |
|  1 |  0 |  1 |  0 |  1 |

### Relevance

- **Truth Tables**: Essential for understanding and designing digital circuits, verifying logic functions, and debugging.
- **K-Maps**: Crucial for simplifying Boolean expressions, optimizing digital circuits, and reducing hardware complexity.

Both tools are fundamental in digital logic design, aiding in the creation of efficient and reliable electronic systems.


### Boolean Expressions from K-Maps

Boolean expressions can be derived from Karnaugh Maps (K-Maps) by grouping adjacent cells with value 1 and writing the corresponding simplified expression.

#### Steps to Derive Boolean Expressions:
1. **Identify Groups**: Group adjacent cells with value 1 into the largest possible power-of-two rectangles (1, 2, 4, 8, etc.).
2. **Write Expressions**: For each group, write the product (AND) term that represents the common variables.
3. **Combine Terms**: Combine all the product terms using the sum (OR) operation to get the final simplified Boolean expression.

#### Example:
For a 3-variable K-Map with variables A, B, and C:

| ABC | 000 | 001 | 011 | 010 | 110 | 111 | 101 | 100 |
|-----|-----|-----|-----|-----|-----|-----|-----|-----|
|  0  |  1  |  1  |  0  |  1  |  0  |  1  |  0  |  1  |

1. **Group 1s**: Identify groups of 1s. For example, group cells (000, 001), (110, 111), and (100, 101).
2. **Write Product Terms**: For each group, write the product term:
    - Group (000, 001): A'B'C + A'B'C' = A'B'
    - Group (110, 111): AB'C + AB'C' = AB'
    - Group (100, 101): A'BC + A'BC' = A'C
3. **Combine Terms**: Combine the product terms using OR:
    - Final Expression: A'B' + AB' + A'C

### Importance

- **Simplification**: Reduces the complexity of digital circuits by minimizing the number of gates required.
- **Optimization**: Helps in designing efficient and cost-effective hardware.
- **Error Reduction**: Simplified expressions are less prone to errors in implementation.

Understanding how to derive Boolean expressions from K-Maps is essential for anyone involved in digital logic design and optimization.

## Simplification Methods for Boolean Expressions

Simplifying Boolean expressions is crucial for optimizing digital circuits. There are several methods to achieve this, including algebraic manipulation, Karnaugh Maps (K-Maps), and the Quine-McCluskey method.

### Algebraic Manipulation

Algebraic manipulation involves using Boolean algebra rules to simplify expressions. Key rules include:

- **Identity Law**: A + 0 = A, A * 1 = A
- **Null Law**: A + 1 = 1, A * 0 = 0
- **Idempotent Law**: A + A = A, A * A = A
- **Complement Law**: A + A' = 1, A * A' = 0
- **Distributive Law**: A * (B + C) = (A * B) + (A * C)
- **Absorption Law**: A + (A * B) = A, A * (A + B) = A
- **De Morgan's Theorems**: (A * B)' = A' + B', (A + B)' = A' * B'

#### Example:
Simplify the expression: A * (A + B)
Using the Absorption Law: A * (A + B) = A

### Karnaugh Maps (K-Maps)

K-Maps provide a visual method for simplifying Boolean expressions by grouping adjacent cells representing minterms. This method is particularly useful for expressions with up to 4-6 variables.

#### Steps:
1. Draw the K-Map grid based on the number of variables.
2. Fill in the cells with the output values from the truth table.
3. Group adjacent cells with value 1 into the largest possible power-of-two rectangles.
4. Write the simplified Boolean expression from the groups.

### Quine-McCluskey Method

The Quine-McCluskey method is a tabular method for simplifying Boolean expressions, suitable for computer implementation and handling more variables than K-Maps.

#### Steps:
1. List all minterms of the Boolean function.
2. Group minterms based on the number of 1s in their binary representation.
3. Combine minterms to eliminate variables, creating prime implicants.
4. Use a prime implicant chart to select essential prime implicants and cover all minterms.

### Comparison of Methods

- **Algebraic Manipulation**: Best for simple expressions and quick simplifications.
- **Karnaugh Maps**: Ideal for visual simplification of expressions with up to 4-6 variables.
- **Quine-McCluskey Method**: Suitable for systematic simplification of complex expressions and computer-aided design.

### Conclusion

Understanding and applying these simplification methods is essential for designing efficient digital circuits. Each method has its strengths and is chosen based on the complexity of the Boolean expression and the specific requirements of the design task.


## Half Adders and Full Adders

### Half Adder

A half adder is a digital circuit that performs the addition of two single-bit binary numbers. It has two inputs, typically labeled A and B, and two outputs: the Sum (S) and the Carry (C).

#### Truth Table:
| A | B | Sum (S) | Carry (C) |
|---|---|---------|-----------|
| 0 | 0 |    0    |     0     |
| 0 | 1 |    1    |     0     |
| 1 | 0 |    1    |     0     |
| 1 | 1 |    0    |     1     |

#### Logic Diagram:
- **Sum (S)**: \( S = A \oplus B \) (XOR gate)
- **Carry (C)**: \( C = A \cdot B \) (AND gate)

### Full Adder

A full adder is a digital circuit that performs the addition of three single-bit binary numbers: two significant bits and an incoming carry bit. It has three inputs, typically labeled A, B, and Carry-in (Cin), and two outputs: the Sum (S) and the Carry-out (Cout).

#### Truth Table:
| A | B | Cin | Sum (S) | Carry-out (Cout) |
|---|---|-----|---------|------------------|
| 0 | 0 |  0  |    0    |        0         |
| 0 | 0 |  1  |    1    |        0         |
| 0 | 1 |  0  |    1    |        0         |
| 0 | 1 |  1  |    0    |        1         |
| 1 | 0 |  0  |    1    |        0         |
| 1 | 0 |  1  |    0    |        1         |
| 1 | 1 |  0  |    0    |        1         |
| 1 | 1 |  1  |    1    |        1         |

#### Logic Diagram:
- **Sum (S)**: \( S = A \oplus B \oplus Cin \) (XOR gates)
- **Carry-out (Cout)**: \( Cout = (A \cdot B) + (Cin \cdot (A \oplus B)) \) (AND and OR gates)

### Carry Over

The carry output in both half adders and full adders is used to handle the overflow bit that results from the addition of binary numbers. In multi-bit binary addition, the carry output from one adder is used as the carry input for the next higher bit adder.

### Building Adders

- **Half Adder**: Constructed using one XOR gate for the Sum and one AND gate for the Carry.
- **Full Adder**: Constructed using two XOR gates, two AND gates, and one OR gate. Alternatively, a full adder can be built using two half adders and an OR gate.

### Applications

- **Arithmetic Operations**: Used in arithmetic logic units (ALUs) for performing binary addition.
- **Digital Counters**: Used in designing binary counters and incrementers.
- **Data Processing**: Essential in digital signal processing and various computational tasks.

Half adders and full adders are fundamental components in digital electronics, enabling the implementation of binary addition and forming the basis for more complex arithmetic operations.

## Flip-Flops

Flip-flops are fundamental building blocks in digital electronics used for storing binary data. They are bistable devices, meaning they have two stable states, which can represent binary 0 and 1. Flip-flops are used in various applications, including data storage, data transfer, and synchronization.

### Types of Flip-Flops

1. **SR Flip-Flop (Set-Reset Flip-Flop)**
2. **D Flip-Flop (Data or Delay Flip-Flop)**
3. **JK Flip-Flop**
4. **T Flip-Flop (Toggle Flip-Flop)**

### SR Flip-Flop

The SR flip-flop has two inputs, Set (S) and Reset (R), and two outputs, Q and Q'. It sets the output to 1 when S is 1 and R is 0, and resets the output to 0 when S is 0 and R is 1.

#### Truth Table:
| S | R | Q (Next State) |
|---|---|----------------|
| 0 | 0 |      Q         |
| 0 | 1 |      0         |
| 1 | 0 |      1         |
| 1 | 1 |    Invalid     |

### D Flip-Flop

The D flip-flop has a single input, D (Data), and it transfers the input to the output Q on the triggering edge of the clock signal.

#### Truth Table:
| D | Q (Next State) |
|---|----------------|
| 0 |       0        |
| 1 |       1        |

### JK Flip-Flop

The JK flip-flop is an enhancement of the SR flip-flop, with inputs J and K. It eliminates the invalid state by toggling the output when both J and K are 1.

#### Truth Table:
| J | K | Q (Next State) |
|---|---|----------------|
| 0 | 0 |       Q        |
| 0 | 1 |       0        |
| 1 | 0 |       1        |
| 1 | 1 |     Q' (Toggle)|

### T Flip-Flop

The T flip-flop has a single input, T (Toggle), and it toggles the output state on the triggering edge of the clock signal when T is 1.

#### Truth Table:
| T | Q (Next State) |
|---|----------------|
| 0 |       Q        |
| 1 |     Q' (Toggle)|

### Applications of Flip-Flops

- **Data Storage**: Used in registers and memory elements to store binary data.
- **Counters**: Used in designing binary counters and frequency dividers.
- **Shift Registers**: Used in shift registers for data transfer and manipulation.
- **Synchronization**: Used in synchronizing asynchronous signals to a clock signal.

Flip-flops are essential components in digital systems, providing the necessary functionality for data storage, transfer, and control.



## Signed Values in Binary

When working with binary numbers, we often need to represent both positive and negative integers. To achieve this, we use **signed values**. The two most common methods for representing signed integers in binary are **sign-and-magnitude** and **two's complement**.

### Signed Representation

In a signed binary representation:

- **Most Significant Bit (MSB)**: The leftmost bit represents the sign of the number.
  - `0` indicates a positive number.
  - `1` indicates a negative number.

For example, in an 8-bit signed binary number:
- `00000101` represents +5.
- `11111011` represents -5.

### 1's Complement

The **1's complement** of a binary number is obtained by inverting all bits (changing `0`s to `1`s and `1`s to `0`s). 

#### Example:

- Original number: `00000101` (which is +5)
- 1's complement: `11111010` (which represents -5 in 1's complement)

#### Properties of 1's Complement:

- Two representations for zero: `00000000` (positive zero) and `11111111` (negative zero).
- Arithmetic operations can be cumbersome because of these two zeros.

### 2's Complement

The **2's complement** method is more widely used for representing signed integers because it resolves the issues of 1's complement. To find the 2's complement of a binary number:

1. Find the 1's complement of the number.
2. Add `1` to the least significant bit (LSB).

#### Example:

- Original number: `00000101` (which is +5)
- 1's complement: `11111010`
- Add `1`: 
  ```
    11111010
    +        1
    ---------
    11111011 (which represents -5 in 2's complement)
  ```

#### Properties of 2's Complement:

- Only one representation for zero: `00000000`.
- Simplifies arithmetic operations (addition and subtraction) since you can directly add binary numbers regardless of their sign.

## Floating Point Numbers

### 32-bit Floating Point Numbers

- **First Bit**: Sign
- **Next 8 Bits**: Exponent
- **Final 23 Bits**: Significance

### Example: 32-bit Floating Point Representation

Given the binary representation: `0 10000100 00000000010000011000111`

#### Breakdown:
1. **First Segment (Sign Bit)**: `0` (positive)
2. **Second Segment (Exponent)**: `10000100` (represents \(2^{-8}\))
3. **Third Segment (Significance)**: `00000000010000011000111` (represents `8391`)

#### Interpretation:
- **Sign**: Positive
- **Exponent**: \(2^{-8}\)
- **Signifgance**: `8391`

This binary representation corresponds to a positive floating-point number with the given exponent and significance.

**other data types**
>Ascii - 32 bit 

>unicode - 16 bit



## Assembly

We use NIOS II wich is Mips-based

### Registers:

Registers store 32-bit binary numbers. They can hold various types of data, including memory addresses, floating-point numbers, ASCII characters, and more.
>register doesnt nesecarily refer to memory adresses

### addressing: 

- **Immediate** - *the actual value*
    - a = a + 1

- **Registered direct** - *the value containined in the register*
    - r14 = r14 + 1

- **Registered indirect** - *the value in the memory location stored in the register*
    - mem[r14]
        - 0(r14)

- **Absolute** - *the value in memory at a specified location*
    - mem[22]
        - 12(r4)

- **Displacement** - *the value in memory at a specified location*
    - mem[r14[+30]]

### Simple Addition with Registers in Assembly

In assembly language, simple addition operations are performed using registers. Registers are small storage locations within the CPU that hold data temporarily for quick access. Here's how you can perform addition using registers in assembly language:

#### Example: Adding Two Numbers

Let's consider adding two numbers stored in registers `R1` and `R2`, and storing the result in register `R3`.

#### Assembly Code:

```assembly
MOV R1, #5    ; Load the value 5 into register R1
MOV R2, #10   ; Load the value 10 into register R2
ADD R3, R1, R2 ; Add the values in R1 and R2, store the result in R3
```

#### Explanation:

1. **MOV R1, #5**: This instruction moves the immediate value `5` into register `R1`.
2. **MOV R2, #10**: This instruction moves the immediate value `10` into register `R2`.
3. **ADD R3, R1, R2**: This instruction adds the values in registers `R1` and `R2`, and stores the result in register `R3`.

#### Result:

After executing the above instructions, the value in register `R3` will be `15` (since `5 + 10 = 15`).

#### Summary:

- **MOV**: Used to load values into registers.
- **ADD**: Used to perform addition of values in registers.

Using registers for arithmetic operations in assembly language allows for efficient and fast computation, as registers are directly accessible by the CPU.


### Instruction Formats: I-Type, R-Type, and J-Type

In assembly language programming, particularly in the context of MIPS architecture, instructions are categorized into different formats based on their structure and the type of operation they perform. The three primary instruction formats are I-Type, R-Type, and J-Type.

#### I-Type (Immediate Type)

I-Type instructions are used for operations that involve immediate values or address calculations. These instructions typically include an opcode, two registers, and an immediate value.

##### Format:
```
| Opcode (6 bits) | Rs (5 bits) | Rt (5 bits) | Immediate (16 bits) |
```

##### Example:
```assembly
ADDI $t1, $t2, 10  ; Add immediate value 10 to the contents of register $t2 and store the result in $t1
```

#### R-Type (Register Type)

R-Type instructions are used for arithmetic and logical operations that involve only registers. These instructions include an opcode, three registers, a shift amount, and a function code.

##### Format:
```
| Opcode (6 bits) | Rs (5 bits) | Rt (5 bits) | Rd (5 bits) | Shamt (5 bits) | Funct (6 bits) |
```

##### Example:
```assembly
ADD $t1, $t2, $t3  ; Add the contents of registers $t2 and $t3 and store the result in $t1
```

#### J-Type (Jump Type)

J-Type instructions are used for jump operations, which alter the flow of control by changing the program counter to a specified address. These instructions include an opcode and an address.

##### Format:
```
| Opcode (6 bits) | Address (26 bits) |
```

##### Example:
```assembly
J 10000  ; Jump to the address 10000
```

#### Summary

- **I-Type**: Used for immediate values and address calculations.
- **R-Type**: Used for arithmetic and logical operations involving registers.
- **J-Type**: Used for jump operations to alter the control flow.

Understanding these instruction formats is crucial for writing and optimizing assembly code, as they define how instructions are encoded and executed by the processor.




























