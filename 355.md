# COMP 355 ADVANCED ALGORITHMS

- Instructor: Matt Superdock
- Notes Written by: Jack Seigerman
- Year: Fall 2024



## Brute Force Algorythms

Design an algorythm that takes a list A and determines the maximum sum of a sublist of A

Example: A = [1, -5, 2, 4, -1, 3, -9]

sublist include:
 [1, -5, 2] sum: -2
 [2, 4] sum: 6
 [2, 4, -1, 3] sum: 8
 [] sum: 0


Brute force algorythm: 


max = 0
for each sublist A[i, i+1, ... (j-1)]   O(n^2)
    if A[i]+A[i+1]+ ... +A[j-1] > max   
    max = A[i] + A[i+1] + ... A[j-1]    O(n)

Big o (# of iterations * time per iteration)

n(n+1)/2 * n = O(n^3)


Faster iterative solution


What do we have to keep track of
max_current //maximum sum ending at current index

for each x in A:    O(n)
    max_current = max_current + x
    if max_current < 0, max_current = 0
    if max_current > max, max = max_current

O(n)


Structural induction

-Let P(s) be a statement, where S a certain kind 
of data structure (eg a list, a tree, graph, set,
Integer)

-suppose that for all S if P(R) holds, for all   inductive hypotheises
proper substructures (smaller than S), R of S,
then P(s) also holds

-Then for all S, P(s) holds

Theorem: for all lists A, mergesort of (A), should return a correctly sorted version of A

proof:

    by Structural induction on A, we may assume
    that mergesort(S) returns a correctly sorted 
    version of S for all proper sublists S of A.
    We have 2 cases:

    Case 1: if length of (A) < 1, A is alreay sorted
    so returning A is correct.

    Case 2: if length of (A) > 1, the code bypasses
    the if statement and creates, A1, A2 wich are proper 
    sublists of A

    By the inductive hypotheises mergesort A1 and mergesort A2
    return correctly sorted versions of A1 and A2.

    Then Merge (A1, A2) is a correctly sorted version of A.

    this completets the induction


    Quickselect: 
        Goal: Given a list A of length n, and an interger k with 0<k<n,
        find the kth smallest element of A.
        (0th smallest element = smallest)

        Example A- [3,1,8,5,3,7,4], k = 3

        you could also sort then take the kth elemnt O(n log n) to solve the same problem
        but can it be done faster

        Idea: choose a pivot, divide A into 3 lists. 

Theorem: 

    for all lists A, all intergers k with 0<=k<=length(A),
    Quickselect(A,k) returns the kth smallest element of A

Proof:

    by Structural induction on A, we may assume that 
    for all proper sublists  A' of A, if 0<j<length of (A)
    then quicksleect (A',j) returns the jth smallest element of A'

    (we count non consective sublists as sublists)

    Note that the list equal contains at least one element, 
    so the other two lists less and greater are  proper sublits of a



Mergesort: o(n log n)

quicksort: worst case O(n^2) expected case: O(n log n) 

quickselect: O(n) expected time, worst case o(n^2)


expected time: for a randomized algorythm average over all possible random choices

average case: average over all possible inputs


adverserial argument

Lets prive B cannot guarentee a win in less than
4 guesses using an adverserial argument. 

Imagine player a can cheat and change their number provided they dont give inconsistent numbers
we keep track of a set of numbers set s of valid numbers remaining

when b asks a question we divide the set of valid remaining numbers into two sets 
S(yes): numbers for which A's answer is yes
S(no): numbers for which A's answer is no

A chooses the answer coresponding to the bigger set.
the new set of valid numbers has size at least S/2

### of questions  |  size of set s
            0   |   16
            1   |   >=8
            2   |   >=4
            3   |   >=2
            4   |   >=1

B cannot guerantee a win in less than 4 questions

given a list A of comparible things  return a sorted version of a

retriction we are only allowed to get info about A using a comparison A[i] vs A[j] like > < =

theorem any comparison based sorting algorythm has worst case time effieceny big omega of N log N
big omega just like big o but for lower bound

f(n) is O(g(n)) if there exists an integer c such that for all n>=N, f(n) <= c * g(n)

f(n) is BIG OMEGA(g(n)) if there exists an integer c such that for all n>=N, f(n) >= c * g(n)

same rules apply for BIG OMEGA same rules apply
BIG THETA is O and BIG OMEGA


adverserial argument 

we commit to using a list wich is  a permutation of the list [1,2,3,4...n]
there are n! different answers

when an algorythm compares A[i] vs a[j], we can make sure the set of remaining
permutations stays at least half as big
the algortytm needs at least log(n!) comparisons.

stirlings aproximation n! ~ square root of 2 pie * (n/e)^n 
log(n!) = BIG OMEGA(log(SQRROOT(2 pi n))* n/e^n)

Insertion sort
    takes O(n+s) time where s is the number of swaps
    
    for i - 0 to n-1
        for j - i down to one
            if A[j] < A[j-1]
                swap A[j] and A[j-1]
            else:
                break
    
    Analysis:

    Every time we do a swap, we have to do a 
    constant time amount of stuff
    -the swap itself
    -decrement j
    -do another comparison A[j]vs A[j-1]

    some steps of the algorytm are still not accounted for
    -initialzing i, incrementing i
    -initialzing j
    -first comparison first time through the inner loop

    every swap fixes one inversion
    the number of swaps you do in insertion sort is equal to the number of inversions
    Insertion sort takes big O of n+k time where k is equal to the numver of inversions

    Insertion sort on a sorted array
    O(n+k) where k is 0

    tree sort- put all of the elements into a binary search tree, take the elements out of the binary search tree
    radix sort - sort a list of integers by grouping digits one at a time
    hashing - using a set/map/dictionary implemented using a hash table


kinds of graphs

undirected- all edges connect both points 
directed- edges can connect one point to another but not to oposite

simple- no loops no parrallel edges
not simple - loops or parrallel edges (self refrnce or multiple edges same two points same direction)

degree of a vertex is the number of neighbors, in a directed graph its the amount of out neighbors (loops count)

List all edges in a directed graph (not nesceraly simple) represented by adjacency list

v= number of vertices 
e= number of edges

for each vertex u of the graph           (going down adjecency list table)
    for each out neighbor v of u         (going across the table through the linked list)
        print (u -> v)


Analysis:
    count total number of iterations of the inner loop: e (the number of edges)

    e iterations o(1)

    together they have o(e)

    some steps are unaccounted for:
        initialzing and advancing this vertex u 
        big theta of v

    total = O(v+e)
    either can be larger

    
a  vertex v is reachable from u if there is a walk or path from u to valid
a walk may have repeated vertex/edges
a path no repetition

Depth first search

DFS(u)
x = stack containing just the vertex u
while x is not empty
    v = result of pop of stack x
    if v is "marked" 
        continue to next generation
    mark v
    for eahc generation w of v
    push w onto x 

    store marks into an array or hash table

    when we are done, the marked verticies are the reachable verticies

    O(v+e) 
    where pushes/pops <= e
    time to initialize array of marks

Breath first searhc

BFS(u)
same as DFS but stack is changed into a queue
stack to queue
pop to dequeue
push to enqueue


BE CLEAR WHAT TO DO WITH RETURN VALUE

Flood fill:

Example: Given a 2-d array of o's and 1's 

111
100
011

input:  cordiantes i and j 
effect: change the value of all pixels of the same color as (i,j)
witch are reachable from (i,j) by pixels all of the same color

algortytm:

represent the image as an undirected graph
vertices are coordinates and we include an edge if two vertices 
are horizontally or vertcially adjacent and have the same color

apply DFS to this graph starting from the given vertex (i,j).
change the color of the marked vertices


reach every vertex from every other vertex: connected
it has 1 component



defenition: (connected, component)

    let G be an undirected graph, 

    -G is connected if every vertex of G
    is reachable from every other vertex of G

    -A component C of a graph G is a maximal set of 
    Vertices of G such that every vertex in c is reachable
    from every other vertex in C

defenition: (strongly connected, strong component)

    Let G be a directed graph 

    -G is Stringly connected if every vertex of G
    is reachable from every other vertex of G

    -A strong component C of a graph G is a maximal set of 
    Vertices of G such that every vertex in c is reachable
    from every other vertex in C

some DAGs have more than one topolgical ordering 
graphs cant have a cycle and have a topological order

theorem: a directed graph G cant have both a cycle and a topological order.

proof: assume for contradiction, that G has both a cycle and a topolgical ordering
    the edges of any cycle can only go left to right, so we can never get back to the starting vertex
    this is a contradiction so the theorem holds, so the theorem is true.


problem: given a directed graph G either find a cycle or find a topolgical ordering

idea: find a source (vertex with no in edges) put it first in the ordering, then
 delete it from the graph, then repeat 

algorithm: modify the adjacency list structure of the graph 
G to also track in-degrees (number of edges into each vertex)

construct a list of sources S (vertices with in degree)

Initialize an empty list O (top ordering)


while S is nonempty
    remove a vertex s from the set S.
    for each out neighbor t of s 
        reduce the in degree of t by 1.
        if in-degree of t becomes 0,
        add t to list of sources S.
    remove s's row from adjecency list structure 
    Append s to O.
if G has no vertices left, return topolgical ordering O.
if G has vertices left, then G has a cycle.*


apply our topolgoical sort / directed cycle algortytm to G
    which gives us a topolgical ordering. 
    check wether each vertex in the ordering has an edge to the next vertex in the ordering.


idea keep following edges backwards until we hit a vertex twice

algorithm 
construct the reversed graph G 
W=[]
v = and vertex of g
while v is unmarked
    mark validprepend v to W
    v = first outneighbor of v in g

c = []
for w in W:
    append w to c
    if w = v break


defenition in an undirected graph G, a spanning tree is a subgraph
 of G which is connected, has no cycles and includes every vertex of G

 connected, has no cycles = tree
 includes every vertex of G = spanning

If a graph has n vertexes any spanning tree has n-1 edges


problem: given a weighted undirected graph, find a spanning tree with minimum total weight

two algorithm ideas: ("greedy algorithm")

kruskal: repeatetley choose the minimum weight edge that doesnt create a cycle.

O(E log(E))
O(E log(v))

prim(jarnik): Build up a tree T starting with a single vertex V, repeatetly 
choose the min weight edge with one end-point in the tree and one endpoint not in the tree

O(E log(E))
O(E log(v))



greedy algorithm- A greedy algorythm is an algorithm that repeatetley makes greedy short-sighted decisions. 

to show a greedy algorithm is incorrect, give a counterexample


problem: given a possible integer N and the goal is determine a way of making exactly n dollars 
using $1 $5 $10  bills using as few bills as possible

example n = 17

on solution 1, 1, 5, 5, 5

optimal solution: 1, 1, 5, 10


algorithm: repetedly take the largest bill that doesnt cause our total to exceed n dollars

makeChange(n)
{
    one, fives, tens = 0
    while total < 10
        if total + 10 <= N
            tens = tens + 1, total = total +10
        else if total + 5 < n
            fives = fives +1, total = total +5
        else:
            ones = ones +1 total = total +1
    return (ones, fives, tens)
}

any optimal solution uses at most 4 ones, otherwise we could exchange 5 
ones for 1 $5 and reduce number of bills

any optimal solution uses at most 1 5 dollar bill, otherwise we can exchange 2
$5 bills for one ten dollar bill

the total amount of money in ones and fives is $9

so we must take as many tens as possible
the total amount of ones is at most 4
the total amount of fives is at most 1


exchange argument 


problem given N, make change with $1's $8's and $10's



Interval scheduling problem

given a list of closed intervals, choose as many as possible such that no two chosen intervals intersect

input [2,6][6,7][1,3]

(if endpoint is another startpoint or vice versa cant take it)

output [6,7] [1,3]

greedy algorythm 

    repeatetley choose an interval not intersecting the intervals already chosen 
    you could:

    earliest start time     false
    earliest end time       true
    shortest run time       false
    latest start time       true
    latest end time         false
    choose randomly         false
    longest run time        false
    fewest conflicts        false

    algorithm

        sort intervals by finsh time

        choosen = []
        finish = -1000000 // finish time of last movie chosen
        for each interval [s,t] in sorted list
            if finish < s:
                append [s,t] to chosen intervals
                finish = T
        return chosen


theorem our greedy algorithm is optimal

proof:
    consider the two solutions a greedy solution a and some other solution B

    (idea transforming solution B into solution A can only make solution B better)

    put the intervals of these two solutions A and B and look for the first place they dont match

   (Case 1) A uses an interval w earlier or equal finish time to B

   (case 2) solution b runs out of intervals

    by repeating this process of making solution b look more and more like solution a we eventually transform b into a, only exchanging or adding intervals.

    multiply two numbers together, split both lists in half

    r=5112 [5,1,1,2] [5,1] [1,2]
    s= 6292 [6,2,9,2] [6,2] [9,2]


    r = ax+B
    s=cx+B


    51 *100 +12
    62*100 +92

   r*s= (ax+b) (cx+d)

   acx^2 + adxm + bcx +bd 

   acx^2 + (ad +bc)x +bd

   use recursive calls to calculate ac ad bc and bd

   on inputs of n digits we do
    4 recursive calls on iputs half the size digits o(n) other work

    total time O(n)^2time



observation: (a+b)(c+d) ac+ad+bc+bd 

ad+bc can be calculated from ac, bd, (a+b)(c+d)
    ad+bc=(a+b)(c+d)-ac-bd

use recursive calls to calculate ac bd (a+b)(c+d)

on inputs of n digits, we do 3 recursive calls on inputs of n/2 digits 
O(n) other work

O(n^1.58)

n,n/2,...1

log n

draw a tree coresponding to teh recursive call levels
label roots with input sizefill nodes with time spent at each nodes
add the numvers along each row overall

n
3n/2
9n/4

n+3n/2+9n/4 ... geometric

a*(r^k-1)/(r-1)

O(n*(3/2)^logN)

x^logby = y^logbx

O(n^log3)

1.58


The recursion theorem

(karasuba a=3, b=2, k=1)

suppose that on imputs of size n, an algorithm does two things

    - a recurseive calls on inputs of size n/b

    -O(n^k) other work 

then the effiecency of the algorithm is:

    case1: a>b^k    O(nlogbk)

    case2: a=b^k    O(n^k log n)

    case3: a<b^k    O(n^k)



mergesort: a=2 b=2 k=1
    a vs b^k= 2 vs 2
    case 2
    O(n log n)

first recursive a=4 b=2 k=1
    4 vs 2
    case 1
    O(n^2)

binary search a=1 b=2 k=0
    1 vs 1
    case 2 
    O(log n)

    
recursince: # of ways to tile a 1xn rectangel

    2 options: start with a green tile on the left   f(n-1)ways to finish
                start with a blue tile  f(n-2) ways to finish

f(n)=# of ways to tile 1xn with 1x1 and 1x3

        1               n=0
f(n)=   1               n=1
        1               n=2
        f(n-1) +f(n-3), n>=3

        or

        1               n=1
        1               n=2
f(n)=   2               n=3
        f(n-1)+ f(n-3), n=4

    
Dynamic Programming

wieghted interval scheduling problem 

Problem Given a list of intervals, each with a numerical weight. 
goal is tro choose a subset of the intervals with the maximum total wieght,
Such that no two chosen intervals intersect

Example: 
    input:  5[2,6], 1[5,7], 3[1,3]
    output: 5

Consider the choise of whether of not to see the 1st showtime for either choice, we are left with a smaller problem

alg sort showtimes by start time

next(i) = the next movie we could use after seeing i 
let f(i) = max value of movies starting at index i 

        0,           i=n
fi =    
        max(f(i+1)), weight(i)+f(next(i))


where f(i+1) is the value if we dont see i 
and where weight(i)+f(next(i)) is the value if we do see the movie
eight of i is enjoyment for this movie where f next of i is enjoyment from optimal choices down the line

example m=5 n=7 k = 19

choice: use a $m or use an $n 

    19

    1. use a 5 left with 14
    2. use a 7 left with 12


efficency 

wheather we use dynamic programming 
    or memoization, efficency will be this
    [# of subproblems] * [time per subproblem]

a subproblem is a smaller input we have to calculate in order to get our answer

#of subproblems K+1
(0,1,2,3...k)

timer per subproblem is O(1) (k+1)*O(1)= O(n)

A=[1,5,12,3]

2 choices: use A[0] or dont use A[0]

left with [5,12,3]      left with [5,12,3]

need sum of 16-1        need a sume of 16

left f(i,k)=a boolean indicating whether it is possible to make a sum of k, from A[i,...,(n-1)]

starting at index i
```
        k=0,            true
f(i,k)={i=A.length(),   false
        f(i++,k-A[i]) or f(i++,k)
```
Analysis
#of subproblems 
i*0,...n    n+1
k*0...T (t+1)
O(n*T)

## flow networks

Defenition: **flow network**
```
A flow network is a weighted directed graph G 
    the weight of an edge e is called its capacity, denoted ce (c subscript e)
    ce >= 0

    one vertex s is called the source
        no edges into s 
    one vertex t is called the sink 
        no edges out of t 
```
Defenition: **Flow**
```
A flow is a function f: from the edges of the graph to real numbers
    (asighn a non negative flow f(e) to each edge e)
    for each edge 0<=f(e)<=ce
    for each vertex v other that s and t the net flow at v must be 0
    (the total flow into v)=(the total flow out of v)
    The value of a flow f is the total flow out of the source s
    (this equals the total flow into the sink vertex t)
```


Defenition: **Cuts**
```
A cut is a partition of the vertcies of the graph g into two sets A and B 
such that the source is in A and the sink is in B
    notation (A,B)
The capacity of a cut (A,B) is the sum of the capacities of all edges from A to B 
    notation c(A,B)
For any flow f and any cut (A,B) the value of the flow is at most the capacity of any cut
```


Given a flow network G and a flow f the residual graph Gf (G subscript f) 
has the same verticies as G and for each edge u -> v in G where the flow is less than the capacity
Gf has an edge U -> v with capacity cu->v f(u->v)

for each edge u->v in G where f(u->v)>0
    G, has an edge v-> u with capacity f(u->v)


Problem: **Given a flow network**
```
    - Maximum flow: find a flow f with maximum possible value

    - Minimum cut: find a cut (A,B) with minimum possible capacity
```
## Maximum Flow

### Definition

**Maximum flow** in a flow network is the greatest possible flow from the source vertex (s) to the sink vertex (t) without violating the capacity constraints on the edges.

### How to Find Maximum Flow

To find the maximum flow in a flow network, you can use the **Ford-Fulkerson algorithm**. The algorithm works as follows:

1. **Initialize Flow**: Start with an initial flow of 0 for all edges.
2. **Find Augmenting Path**: While there exists an augmenting path from the source (s) to the sink (t) in the residual graph, do the following:
    - Use BFS or DFS to find the path.
    - Determine the minimum capacity along this path (bottleneck capacity).
3. **Update Flow**: For each edge in the augmenting path:
    - If the edge is a forward edge, increase the flow by the bottleneck capacity.
    - If the edge is a backward edge, decrease the flow by the bottleneck capacity.
4. **Repeat**: Repeat steps 2 and 3 until no more augmenting paths can be found.

### Efficiency

The efficiency of the Ford-Fulkerson algorithm depends on the number of iterations and the time per iteration:
- **Number of Iterations**: At most equal to the value of the maximum flow.
- **Time per Iteration**: O(V + E), where V is the number of vertices and E is the number of edges.

Thus, the overall time complexity is O(V * E * f*), where f* is the value of the maximum flow.

### Example

Consider a flow network with vertices and edges with capacities. By applying the Ford-Fulkerson algorithm, you can iteratively find augmenting paths and update the flow until the maximum flow is achieved.





### **the ford-fulkerson algorythm**  *(solves both problems)*

- Ideas: repeatedly find a path from s to t along wich we can push more flow

*Pseudocode:*

    start with f(e)=0 for all edges e 
    //(a flow of zero)

    while (there is a path p from s to t in the residual graph of f):
    //path can be found using BFS or DFS

        for each edge e in p:

            if (e is a "forward" edge):
                f(e) = f(e) + 1

            else if (e is a "backwards" edge):
                f(e) = f(e) - 1

    Let A be the set of all verticies reachable across s in G of f

    Let B be the set of all other vertices

    then v(f) = c(A,B) so: 
        - f is a max flow
        - (A,B) is a min cut

**efficency:**  

    [number of iterations] * [time per iteration]

where number of iterations <= value of max flow 
v(f*)

and time per iteration is O(V+E) (assuming graph is connected)
E>=V-1 (so basically O(E))

**therefore effiencey of total aglorythm is:** O(V(f*)E)

### Bipartite Matching problem

- Problem:
    - matching traininers to pokemon 
    - m trainers
    - n pokemon
    - m<=n
    - each traininer will submit a list of pokemon they like

**Goal** *Match each trainer to a different pokemon on their list or report there is no matching*

- Example:
    - trainers: Ash, Gary, Blue
    - Pokemon: bulbasour, charmander, squirtle

**Algorithm**

given the inputs we construct a flow network

one vertex for each trainer (a) and one vertex for each pokemon (j)

where S (source) connects to each trainer a and each trainer connects to the set of pokemon they want, then each pokemon has a flow of 1 to T (drain)


- call furd-fulkerson on G 
    - if the max flow has value m, then there is a matching:
        - trainer i gets matched to pokemon j if f(ai->pj)=1
    - if max flow has value less than m then there is no matching

**Efficency**

- build a flow network O(V + E)
- number of vertices V = m + n + 2
- number of edges E <= m + n + mn = O(mn)

max flow

    O(v(f*)E)
    where
    v(f*)<= m
    E = O(mn)

    O(m^2*n)

### Example

    you are now given m trainers, n Pokemon, and p accessories that Pokemon can wear (e.g., sunglasses, hat, carrying bag). As before, the trainers each submit a list of Pokemon they like. The goal is to match each trainer with one Pokemon and one accessory for that Pokemon. There is an unlimited number of each Pokemon available, but a Pokemon must be matched with a different accessory each time it is used, and each accessory may be used at most 3 times total. Draw a flow network representing this problem.

![PokemonFlowNetwork ](/assets/pokemonFlowNetwork.png)

v(f)=3

run ford fulkerson if the flow doesnt have a value of n its impossible, but if it does you should take the max flow and decompose it into multiple paths from s, t(i), p(j), a(k), t

### Problem Edge-disjoint paths

Given a directed graph G verticies s, v, t of G

***Goal*** find as many *edge disjoint* paths as possible from s to t

any two paths are allowed to share verticies but no edges

**Algorythm**
- if there are any edges into s or out of t delete them
- assign a capacity of 1 on each edge
- call s the source and t the sink
- call Ford- Fulkerson algorythm, we get a maximum flow F

        while v(F)>0

        form a path from s to t by repeatetly following edges with positive flow

        if we get a cycle, delete the cycle from the flow

        if we dont get a cycle, delete path from the flow

        (reduce flow by 1 one each edge followed)

   >this gives v(F) edge-disjoint paths

### Flow Decomposition:

A flow of value v(F) can be decomposed into:
- V(F) paths from s to t, and
- some number of cycles

### project selection problem 

Input: A list of projects, each with a certain net profit. along with a certian net profit along with dependencies between projects 

Output: Choose projects to do with maximum total profit

Idea: Use mimimum cut

> Reduction: Solve one problem using another problem. "Reduce problem B to problem A" Reduce project selection to min cut problem

Add verticies s and t. Edges from s to each profitable project Edges from each costly project to t.

- a cut (s,t) represents choosing all projects in the set S.

- make all projects dependencies edges u -> v have capacity infinity so we will never choose u to be in s and v to be in t (not having a dependency)

- cut (s,t) includes:
    - edges from chosen costly porjects to T
    - edges from s to not-chosen profitable projects

- capacities of edges from s penalize not choosing each profitable project
- capacities of edges to t penalize choosing each costly project

slecting jobs in s earns a total profit of 

    [sum of profits of all profitable jobs - capacity of (s,t)]

![projectFlowNetwork](/assets/flowNetworkProjectSelection.png)

### Maximum size independent set

Brute force algorithm:

    for every subset of verticies of the graph, 
    check if its an independent set,
    Return the largest independent set 

how many subsets of verticies are there? (n = # of verticies)

> efficency is O(2^n * n^3)

### p vs np problem

polynomial tim eis an alg that runs in O(n^c) for some constant c

p=np every problem can be checked effecintly can also be solved efficencey

p!=np there are many problem that can be checked efficently but not solved efficently

### Defenition: A problem consists of two things, 
*(e.g. independent set, vertex cover)*
- a set of inputs, along with a way to measure the size of an input
    - (e.g. n = length of the list)
    - (e.g. n = # of bits used to represent the input)
- a boolean output for each input

**problem vs algorythm**

sorting - insertion sort

max flow - Ford Fulkerson

### Defenition: A problem X polynomial time reduces to a problem Y is there is an algorythm X in polynomial time, which may use a "oracle" for Y, wich gives answers to problem Y in one unit of time

*X <=<sub>p</sub> Y*

INDEPENDENT SET vs VERTEX COVER

- INDEP - given graph G, integer K, does G have an independent set of size k?
- VERT - give G, K, does G have a vertex cover of size k?

*vertex group is independent set if and only if its complement is a vertex cover*

INDEPENDENT SET <=<sub>p</sub> VERTEX COVER

Reduction: given G, K want to know if G has an independent set of size k

plug in G and v-k to a black box for VERTEXCOVER
return the result